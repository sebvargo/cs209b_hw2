{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <img style=\"float: left; padding-right: 10px; width: 45px\" src=\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/iacs.png\"> Data Science 2: Advanced Topics in Data Science \n",
    "\n",
    "## Homework 2: Bayesian Analysis\n",
    "\n",
    "\n",
    "\n",
    "**Harvard University**<br/>\n",
    "**Spring 2022**<br/>\n",
    "**Instructors**: Mark Glickman & Pavlos Protopapas\n",
    "\n",
    "\n",
    "<hr style=\"height:2pt\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'IPython.core.discondplay'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/vargas/Desktop/cs209b_hw2/cs109b_hw2.ipynb Cell 2'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/vargas/Desktop/cs209b_hw2/cs109b_hw2.ipynb#ch0000001?line=0'>1</a>\u001b[0m \u001b[39m# RUN THIS CELL \u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/vargas/Desktop/cs209b_hw2/cs109b_hw2.ipynb#ch0000001?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mrequests\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/vargas/Desktop/cs209b_hw2/cs109b_hw2.ipynb#ch0000001?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mIPython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdiscondplay\u001b[39;00m \u001b[39mimport\u001b[39;00m HTML\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/vargas/Desktop/cs209b_hw2/cs109b_hw2.ipynb#ch0000001?line=3'>4</a>\u001b[0m styles \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39mget(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/vargas/Desktop/cs209b_hw2/cs109b_hw2.ipynb#ch0000001?line=4'>5</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mhttps://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/vargas/Desktop/cs209b_hw2/cs109b_hw2.ipynb#ch0000001?line=5'>6</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcontent/styles/cs109.css\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/vargas/Desktop/cs209b_hw2/cs109b_hw2.ipynb#ch0000001?line=6'>7</a>\u001b[0m )\u001b[39m.\u001b[39mtext\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/vargas/Desktop/cs209b_hw2/cs109b_hw2.ipynb#ch0000001?line=7'>8</a>\u001b[0m HTML(styles)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'IPython.core.discondplay'"
     ]
    }
   ],
   "source": [
    "# RUN THIS CELL \n",
    "import requests\n",
    "from IPython.core.discondplay import HTML\n",
    "styles = requests.get(\n",
    "    \"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/\"\n",
    "    \"content/styles/cs109.css\"\n",
    ").text\n",
    "HTML(styles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"instructions\"></a>\n",
    "\n",
    "<hr style=\"height:2pt\">\n",
    "\n",
    "### INSTRUCTIONS\n",
    "\n",
    "- This homework can be submitted **in pairs**.\n",
    "\n",
    "- To submit your assignment follow the instructions given in Canvas.\n",
    "\n",
    "- Please **restart the kernel and run the entire notebook again before you submit. But remember that it can take a long time to run, so give yourself enough time.** \n",
    "\n",
    "- Running cells out of order is a common pitfall in Jupyter Notebooks. To make sure your code continues to work, restart the kernel and rerun your notebook periodically while working through this assignment. \n",
    "\n",
    "- We have tried to include all the libraries you may need to do the assignment in the imports cell provided below. **Please use only the libraries provided in those imports.**\n",
    "\n",
    "- Please use `.head(...)` when viewing data. Do not submit a notebook that is **excessively long**. \n",
    "\n",
    "- In questions that require code to answer, such as \"calculate and report $R^2$\", do not just output the value from a cell. Write a `print(...)` function that clearly labels the output, includes a reference to the calculated value, and rounds it to a reasonable number of digits. **Do not hard code values in your printed output**. For example, this is an appropriate print statement:\n",
    "```python\n",
    "print(f'The R^2 is {R:.4f}')\n",
    "```\n",
    "- **Your plots MUST be clearly labeled and easy to read,** including clear labels for the $x$ and $y$ axes, a descriptive title (\"MSE plot\" is NOT a descriptive title; \"Training and validation MSE at varying degree polynomial regression models\" on the other hand is descriptive), a legend when appropriate, and clearly formatted text and graphics.\n",
    "\n",
    "- **Your code may also be evaluated for efficiency and clarity.** As a result, correct output is not always sufficient for full credit.\n",
    "\n",
    "<hr style=\"height:2pt\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyMC3 version: 3.11.4\n",
      "Using ArviZ version: 0.11.4\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from datetime import datetime as dt\n",
    "\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc3 as pm\n",
    "from scipy.special import expit\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "print(f\"Using PyMC3 version: {pm.__version__}\")\n",
    "print(f\"Using ArviZ version: {az.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore a common pymc3 warning that comes from library functions, not our code.\n",
    "# Pymc3 may throw additional warnings, but other warnings should be manageable\n",
    "# by following the instructions included within the warning messages.\n",
    "import warnings\n",
    "\n",
    "messages=[\n",
    "    \"Using `from_pymc3` without the model will be deprecated in a future release\",\n",
    "]\n",
    "\n",
    "for m in messages:\n",
    "    warnings.filterwarnings(\"ignore\", message=m)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"contents\"></a>\n",
    "\n",
    "## Notebook Contents\n",
    "\n",
    "- [**Part 1: Rejection sampling and the weighted bootstrap**](#part1)\n",
    "  - [Overview](#part1intro)\n",
    "  - [Questions](#part1questions)\n",
    "  - [Solutions](#part1solutions)\n",
    "\n",
    "\n",
    "- [**Part 2: Bayesian Logistic Regression and Varying-Intercepts Model**](#part2)\n",
    "  - [Overview](#part2intro)\n",
    "  - [Questions](#part2questions)\n",
    "  - [Solutions](#part2solutions)\n",
    "\n",
    "\n",
    "- [**Part 3: Varying-Coefficients Model and Model Selection**](#part3)\n",
    "  - [Overview](#part3intro)\n",
    "  - [Questions](#part3questions)\n",
    "  - [Solutions](#part3solutions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contraceptive Usage by Bangladeshi Women\n",
    "\n",
    "For this assignment, you are provided with data sets `dataset_2_train.csv` and `dataset_2_test.csv`containing details of contraceptive usage by 1,934 Bangladeshi women.\n",
    "\n",
    "There are four attributes for each woman, along with a label `contraceptive_use` indicating if she uses contraceptives. The attributes include:\n",
    "\n",
    "* `district`: identifying code for the district the woman lives in\n",
    "* `urban`: type of region of residence\n",
    "* `living.children`: number of living children\n",
    "* `age-mean`: age of the woman (in years, centered around mean)\n",
    "\n",
    "The women are grouped into 60 districts. The task is to build a classification model that can predict if a given woman uses contraceptives.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part1\"></a>\n",
    "    \n",
    "<!-- <div class=\"alert alert-block alert-danger\" style=\"color:black;background-color:#E7F4FA\"> -->\n",
    "\n",
    "# Part 1:  Rejection sampling and the weighted bootstrap\n",
    "\n",
    "[Return to contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part1intro\"></a>\n",
    "\n",
    "## Overview \n",
    "\n",
    "[Return to contents](#contents)\n",
    "\n",
    "For the first part of the problem, we will only work with the label `contraceptive_use` and ignore all the attributes.  Let $Y_i$ be 1 if woman $i$ uses contraceptives, and 0 otherwise.  Assume a Bernoulli model for the data:\n",
    "\n",
    "$$Y_{i} \\sim \\text{Bernoulli}(\\theta)$$\n",
    "\n",
    "where $i=1,\\ldots,N$, with $N$ being the number of observations in the training data set, and $\\theta$ is the unknown probability a woman uses contraception.  We will assume the following prior distribution on $\\theta$:\n",
    "\n",
    "$$\\theta \\sim \\text{Normal}(0.5, 0.5^2)$$\n",
    "\n",
    "subject to $0 \\leq \\theta \\leq 1$.  This is sometimes called a truncated normal distribution.  A value from this distribution can be randomly drawn by simulating a value from $\\text{Normal}(0.5, 0.5^2)$ and then keeping it if the value is between 0 and 1, and trying again if it is outside this range.  In fact, this is a form of rejection sampling.  The density for the truncated normal distribution is\n",
    "\n",
    "$$p(\\theta) = c\\times\\frac{1}{\\sqrt{2\\pi (0.5)^2}} \\: \\exp\\left(\\frac{-1}{2(0.5)^2}(\\theta-0.5)^2\\right) \\; \\text{for} \\; 0\\leq \\theta \\leq 1 \\; \\text{, and} \\; 0 \\; \\text{otherwise,}$$\n",
    "\n",
    "where $c$ is a normalizing constant that does not depend on $\\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part1questions\"></a>\n",
    "\n",
    "### <div class='exercise'>Part 1: Questions</div> \n",
    "\n",
    "[Return to contents](#contents)\n",
    "\n",
    "**1.1** Given the training data, what is the likelihood function $L(\\theta | y_1,\\ldots,y_n)$?  What is the MLE of $\\theta$ as a function of the $y_1,\\ldots,y_n$?  Compute the MLE from the data.\n",
    "\n",
    "**1.2** Using rejection sampling, simulate a sample of 10,000 accepted values $\\theta$ from the posterior distribution.  Plot a histogram of these values, and provide numerical summaries of the distribution of the 10,000 values. Interpret your findings.\n",
    "\n",
    "**Note: make sure $\\theta$ only takes on values which are valid for the parameter it represents and that all samples that do not pass the sampling criterion are rejected. Consult the lecture notes on rejection sampling if you need to review this criterion.**\n",
    "\n",
    "**1.3** Carry out the weighted bootstrap to simulate 1,000 values of $\\theta$ from the posterior distribution.  In doing so, simulate 10,000 values from the prior distribution to use as the discrete distribution from which the posterior draws will be simulated via the importance weights.  As above, plot a histogram of these values, and provide numerical summaries of the distribution of 1,000 values.  Interpret the results, and compare to the results of rejection sampling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part1solutions\"></a>\n",
    "\n",
    "## Part 1: Solutions\n",
    "\n",
    "[Return to contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "def read_data(filename = 'data/dataset_2_train.csv', train = True):\n",
    "    if train:\n",
    "        data = pd.read_csv(filename)\n",
    "    return data\n",
    "\n",
    "\n",
    "def trunc_normal(n = 10, mean = 0.5, std_dev = 0.5, min = 0, max = 1):\n",
    "    '''\n",
    "    Returns n from a normal distribution ~N(mean, std_dev^2) truncated between min and max\n",
    "    '''\n",
    "    x_trunc = []\n",
    "    while len(x_trunc) < n:\n",
    "        x = np.random.normal(loc=mean, scale = std_dev)\n",
    "        if (x >=min and x<=max):\n",
    "            x_trunc.append(x)\n",
    "        \n",
    "    if len(x_trunc) == 1:\n",
    "        return x_trunc[0]\n",
    "    \n",
    "    return x_trunc\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise-r'>\n",
    "\n",
    "**1.1.a**  Given the training data, what is the likelihood function $L(\\theta | y_1,\\ldots,y_n)$?  \n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer\n",
    "\n",
    "Per the problem statement:\n",
    "$$\n",
    "Y_i = \n",
    "\\begin{cases}\n",
    "1    &\\text {if the $i$-th woman uses contraceptives} \\\\\n",
    "0 & \\text {otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "We know that the probability model for a Bernoulli distribution is as follows:\n",
    "\n",
    "\n",
    "$$\n",
    "P(Y_i = y | \\theta)=\n",
    "\\begin{cases}\n",
    "\\theta    &\\text {for } y = 1\\\\\n",
    "1 - \\theta & \\text {for } y=0\\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Equivalent to:\n",
    "\\begin{aligned}\n",
    "P(Y_i = y | \\theta)\n",
    "&= \\theta^{y_i} (1-\\theta)^{1-y_i}\n",
    "\\end{aligned}\n",
    "\n",
    "Where $\\theta$ is the unknown probability a woman uses contraception.\n",
    "\n",
    "We get the likelihood function by calculating the probability of the data conditional on $\\theta$, viewed as a function of the parameter:\n",
    "\\begin{aligned}\n",
    "L(\\theta | y_1, y_2, ... , y_n)\n",
    "&=p(y_1, y_2, ... , y_n | \\theta)\\\\\n",
    "&= P(Y_1 = y_1 | \\theta) \\cdot P(Y_2 = y_2 | \\theta) \\cdot \\ldots P(Y_n = y_n | \\theta) \\\\ \n",
    "&= \\prod_{i=1}^n P(Y_i = y_i | \\theta) \\\\\n",
    "&= \\prod_{i=1}^n\\theta^{y_i}  (1-\\theta)^{1-y_i}\n",
    "\\end{aligned}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise-r'>\n",
    "\n",
    "**1.1.b**   What is the MLE of $\\theta$ as a function of the $y_1,\\ldots,y_n$?  Compute the MLE from the data.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Answer\n",
    "We will take the log of $L(\\theta | y_1, y_2, ... , y_n)$ because it simplifies working with the expression:\n",
    "\n",
    "\\begin{aligned}\n",
    "\\ln({L(\\theta | y_1, y_2, ... , y_n)})\n",
    "&= \\ln \\left(\\prod_{i=1}^n\\ \\theta^{y_i}  (1-\\theta)^{1-y_i}  \\right)\\\\\n",
    "&= \\sum_{i=1}^n \\left[ y_i \\ln{\\theta} + (1-y_i) \\ln{(1-\\theta)} \\right]\\\\\n",
    "&=  \\left(y_1 \\ln(\\theta) + (1-y_1) \\ln(1-\\theta) \\right)  + \\ldots + \\left( y_n \\ln(\\theta) + (1-y_n) \\ln(1-\\theta) \\right)\\\\\n",
    "&=(y_1 + y_2 + ... + y_n)  \\cdot \\ln(\\theta) + [n - (y_1 + y_2 + ... + y_n)]\\cdot \\ln(1-\\theta) \n",
    "\\end{aligned}\n",
    "\n",
    "\n",
    "Letting $Y_i = (y_1 + y_2 + ... + y_n)$: \n",
    "\\begin{aligned}\n",
    "\\ln({L(\\theta | Y_i)}) \n",
    "&=(Y_i)  \\cdot \\ln(\\theta) + [n - Y_i]\\cdot \\ln(1-\\theta) \n",
    "\\end{aligned}\n",
    "\n",
    "The MLE is occurs at a value of \\theta where:\n",
    "\n",
    "\\begin{aligned}\n",
    "0  \n",
    "&= \\frac{d\\ln({L(\\theta | Y_i)}}{d\\theta} \\\\\n",
    "&=\\frac{d} {d\\theta} \\left[(Y_i)  \\cdot \\ln(\\theta) + [n - Y_i]\\cdot \\ln(1-\\theta) \\right] \\\\ 0\n",
    "&=  \\frac{Y_i}{\\theta} - \\frac{n - Y_i}{1-\\theta} \n",
    "\\end{aligned}\n",
    "\n",
    "Finally we solve for $\\theta_{MLE}$:\n",
    "$$\n",
    "\\theta_{MLE} = \\frac{Y_i}{n} = \\frac{y_1 + y_2 + ... + y_n} {n}\n",
    "$$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise-r'>\n",
    "\n",
    "**1.1.c**   Compute the MLE from the data.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_data()\n",
    "n = df.shape[0]\n",
    "y_i = df['contraceptive_use'].sum()\n",
    "mle = y_i/n\n",
    "print(f'The MLE is {mle:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise-r'>\n",
    "\n",
    "**1.2**  Using rejection sampling, simulate a sample of 10,000 accepted values $\\theta$ from the posterior distribution.  Plot a histogram of these values, and provide numerical summaries of the distribution of the 10,000 values. Interpret your findings.\n",
    "\n",
    "**Note: make sure $\\theta$ only takes on values which are valid for the parameter it represents and that all samples that do not pass the sampling criterion are rejected. Consult the lecture notes on rejection sampling if you need to review this criterion.**\n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L(theta, alpha, beta):\n",
    "    l = (theta**(alpha-1)) * ((1-theta)**(beta-1))\n",
    "    return l\n",
    "\n",
    "df = read_data()\n",
    "n = df.shape[0]\n",
    "mle = y_i/n\n",
    "y_i = df['contraceptive_use'].sum()\n",
    "\n",
    "alpha, beta = (y_i+1, n-y_i + 1)\n",
    "\n",
    "\n",
    "print(\"Data has {} rows\".format(n))\n",
    "print(\"Alpha = {}\".format(alpha))\n",
    "print(\"Beta = {}\".format(beta))\n",
    "\n",
    "samples = 10000 # number of samples to draw\n",
    "mu, sigma = (0.5, 0.5)\n",
    "M  = L(mle, alpha, beta)\n",
    "thetas = []\n",
    "\n",
    "while len(thetas) <samples:\n",
    "    # simulate theta from p(theta)\n",
    "    \n",
    "    theta = trunc_normal(n = 1, mean = mu, std_dev = sigma, min = 0, max = 1)\n",
    "    \n",
    "    # generate U from uniform distribution\n",
    "    U = np.random.uniform(0, 1)\n",
    "    \n",
    "    # likelihood\n",
    "    likelihood = L(theta, alpha, beta)\n",
    "    likelihood_M = likelihood/M\n",
    "    \n",
    "    # acceptance check\n",
    "    accept = likelihood_M >= U\n",
    "\n",
    "    if accept:\n",
    "        thetas.append(theta)\n",
    "\n",
    "thetas = np.array(thetas)\n",
    "plt.hist(thetas, bins = 100)\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('$\\\\theta$')\n",
    "plt.title('Histogram of accepted $\\\\theta$ values from posterior distribution')\n",
    "plt.show()\n",
    "\n",
    "mean = thetas.mean()\n",
    "var = thetas.var()\n",
    "std = thetas.std()\n",
    "median = np.median(thetas)\n",
    "print('Summary of 10,000 sampled and accepted values of $\\\\theta$')\n",
    "print(' - Mean = {:.5f}'.format(mean))\n",
    "print(' - Variance = {:.5f}'.format(var))\n",
    "print(' - Std. Dev = {:.5f}'.format(std))\n",
    "print(' - Median = {:.5f}'.format(median))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These simulated results, drawn from the posterior distribution, suggest that the probability that a woman uses contraception is closer to 0.39 than to the 0.5 initially assumed in the prior distribution $\\theta$. \n",
    "Our prior distribution should be updated to $\\theta \\sim \\text{Normal}(0.39, 0.015^2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise-r'>\n",
    "\n",
    "**1.3**  Carry out the weighted bootstrap to simulate 1,000 values of $\\theta$ from the posterior distribution.  In doing so, simulate 10,000 values from the prior distribution to use as the discrete distribution from which the posterior draws will be simulated via the importance weights.  As above, plot a histogram of these values, and provide numerical summaries of the distribution of 1,000 values.  Interpret the results, and compare to the results of rejection sampling.\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "samples = 10000 # number of samples to draw\n",
    "mu, sigma = (0.5, 0.5)\n",
    "thetas = np.array(trunc_normal(n = samples, mean = mu, std_dev = sigma, min = 0, max = 1))\n",
    "likelihood = L(thetas, alpha, beta)\n",
    "weights = likelihood/likelihood.sum()\n",
    "v = random.choices(thetas,weights=weights,k=samples)\n",
    "\n",
    "thetas = np.array(v)\n",
    "plt.hist(thetas, bins = 100)\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('$\\\\theta$')\n",
    "plt.title('Histogram of accepted $\\\\theta$ values from posterior distribution')\n",
    "plt.show()\n",
    "\n",
    "mean = thetas.mean()\n",
    "var = thetas.var()\n",
    "std = thetas.std()\n",
    "median = np.median(thetas)\n",
    "print('Summary of 10,000 sampled and accepted values of $\\\\theta$')\n",
    "print(' - Mean = {:.5f}'.format(mean))\n",
    "print(' - Variance = {:.5f}'.format(var))\n",
    "print(' - Std. Dev = {:.5f}'.format(std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the rejection sampling, with the bootstrap approach we find that the probability that a woman uses contraception is closer to 0.39 than to the 0.5 initially assumed in the prior distribution $\\theta$. The only noticeable difference in the statistics is a slight change in the standard deviation, implying that the bootstrap method brings more uncertainty.\n",
    "Our prior distribution should be updated to $\\theta \\sim \\text{Normal}(0.39, 0.016^2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part2\"></a>\n",
    "    \n",
    "<!-- <div class=\"alert alert-block alert-danger\" style=\"color:black;background-color:#E7F4FA\"> -->\n",
    "\n",
    "# Part 2: Bayesian Logistic Regression and Varying-Intercepts Model\n",
    "\n",
    "[Return to contents](#contents)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part2intro\"></a>\n",
    "\n",
    "## Overview \n",
    "\n",
    "[Return to contents](#contents)\n",
    "\n",
    "The second model we will fit to the contraceptives data is a varying-intercept logistic regression model, where the intercept varies by district.\n",
    "\n",
    "Prior distributions:\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "\\beta_{0j} &\\sim N(\\mu_0,\\sigma_0^2)\\; \\text{, with} \\;\\; \\mu_0 \\sim N(0,10000)\\; \\text{and} \\; \\; \\frac{1}{\\sigma^2_0} \\sim \\text{Gamma}(0.1,0.1)\n",
    "\\\\\n",
    "\\beta_1 &\\sim N(0,10000) \n",
    "\\\\ \\\\ \n",
    "\\beta_2 &\\sim N(0,10000)\n",
    "\\\\ \\\\ \n",
    "\\beta_3 &\\sim N(0,10000)\n",
    "\\\\ \\\\\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "Model for data:\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "Y_{ij} & \\sim \\text{Bernoulli}(p_{ij})\n",
    "\\\\ \\\\\n",
    "\\text{logit}\\:p_{ij} &= \\beta_{0j} + \\beta_1 \\times \\text{urban} + \\beta_2 \\times \\text{living.children} + \\beta_3 \\times \\text{age-mean}\n",
    "\\\\ \\\\\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "Where $Y_{ij}$ is 1 if woman $i$ in district $j$ uses contraceptives, and 0 otherwise, and where $i \\in \\{1,...,N\\}$ and $j \\in \\{1,...,J\\}$. $N$ is the number of observations in the data, and $J$ is the number of districts. The above notation assumes $N(\\mu, \\sigma^2)$ is a Normal distribution with mean $\\mu$ and variance $\\sigma^2$.\n",
    "\n",
    "**PLEASE NOTE:** The $\\text{Gamma}$ distribution cited above, uses the $\\text{Gamma}(\\alpha, \\beta)$ parametrization, where $\\alpha$ is the shape and $\\beta$ is the rate.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part2questions\"></a>\n",
    "\n",
    "### <div class='exercise'>Part 2: Questions</div> \n",
    "\n",
    "[Return to contents](#contents)\n",
    "\n",
    "\n",
    "**2.1** As a preprocessing step, map the district number 61 to the number 54 so that the numbering is consecutive with no gaps. Also, re-name district 60 to be district 0 so that the districts are now numbered 0 through 59. **We use this numbering throughout the homework, and will grade using these district numbers**\n",
    "\n",
    "**2.2** We should verify that pymc3 can indeed recover the hidden parameter values. To do this, we'll hard-code known values of our choosing for the model parameters and simulate data from the model. Then, using this simulated data, we'll check if pymc3 can get back the parameter values we hard-coded. If it does, we'll have hope that it can get the hidden parameter values that generated the real data.\n",
    "\n",
    "**Note: These hard-coded parameters will be used in question 2.2 - 2.5**.\n",
    "\n",
    "Use the following hard-coded values:\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "\\mu_0 &= 2\n",
    "\\\\ \\\\\n",
    "\\sigma^2_0 &= 1\n",
    "\\\\ \\\\\n",
    "\\beta_{0j} &\\sim N(\\mu_0,\\sigma_0^2) \\; \\text{for all sixty districts}\n",
    "\\\\ \\\\\n",
    "\\beta_1 &= 4\n",
    "\\\\ \\\\ \n",
    "\\beta_2 &= -3\n",
    "\\\\ \\\\\n",
    "\\beta_3 &= -2\n",
    "\\\\ \\\\\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "**Verify that these parameters generate data in which an average of 46 to 48 percent of subjects use contraceptives.**\n",
    "\n",
    "**2.3** Fit the varying-intercept model specified above to your simulated data. Reasonably good convergence may require adjustments to the number of tuning samples and the target acceptance rate as suggested in pymc3's warnings.\n",
    "\n",
    "**2.4** Plot the trace plots of the MCMC sampler for the parameters $\\mu_0, \\frac{1}{\\sigma^2_0}\\text{ (a.k.a., }\\tau_0\\text{)}, \\beta_1, \\beta_2, \\beta_3$. Based on these and the R-hat values, does it look like the samplers converged?\n",
    "\n",
    "**2.5** Plot histograms of the posterior distributions for the parameters $\\beta_{0,9}$, $\\beta_{0,19}$, $\\beta_{0,29}$, ..., $\\beta_{0,59}$. Are the actual parameters that you generated contained within these posterior distributions?\n",
    "\n",
    "**Hint: The `az.plot_posterior()` function might be helpful here.**\n",
    "\n",
    "**2.6** We now fit our model to the *actual* data. Fit the varying-intercept model to the real training data.\n",
    "\n",
    "**2.7** Check the convergence by examining the trace plots and R-hats, as you did with the simulated data. What do you observe?\n",
    "\n",
    "**2.8** Based on the posterior means, which district has the highest base rate of contraceptive usage (independent of other factors like urban population)? Which district has the lowest?\n",
    "\n",
    "**2.9** What are the posterior means of $\\mu_0$ and $\\sigma_0$? Do these values offer any evidence in support of or against the varying-intercept model, compared to a model with a single intercept value for all districts?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id=\"part2solutions\"></a>\n",
    "\n",
    "## Part 2: Solutions\n",
    "\n",
    "[Return to contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise-r'>\n",
    "\n",
    "**2.1**  As a preprocessing step, map the district number 61 to the number 54 so that the numbering is consecutive with no gaps. Also, re-name district 60 to be district 0 so that the districts are now numbered 0 through 59. **We use this numbering throughout the homework, and will grade using these district numbers**\n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_part2():\n",
    "    # your code here\n",
    "    df = read_data()\n",
    "\n",
    "    # map district 61 to 54\n",
    "    df['district'] = df['district'].replace(61,54)\n",
    "\n",
    "    # rename district 60 to 0\n",
    "    df['district'] = df['district'].replace(60,0)\n",
    "    \n",
    "    return df\n",
    "\n",
    "data = read_data_part2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise-r'>\n",
    "\n",
    "**2.2**  We should verify that pymc3 can indeed recover the hidden parameter values. To do this, we'll hard-code known values of our choosing for the model parameters and simulate data from the model. Then, using this simulated data, we'll check if pymc3 can get back the parameter values we hard-coded. If it does, we'll have hope that it can get the hidden parameter values that generated the real data.\n",
    "\n",
    "**Note: These hard-coded parameters will be used in question 2.2 - 2.5**.\n",
    "\n",
    "Use the following hard-coded values:\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "\\mu_0 &= 2\n",
    "\\\\ \\\\\n",
    "\\sigma^2_0 &= 1\n",
    "\\\\ \\\\\n",
    "\\beta_{0j} &\\sim N(\\mu_0,\\sigma_0^2) \\; \\text{for all sixty districts}\n",
    "\\\\ \\\\\n",
    "\\beta_1 &= 4\n",
    "\\\\ \\\\ \n",
    "\\beta_2 &= -3\n",
    "\\\\ \\\\\n",
    "\\beta_3 &= -2\n",
    "\\\\ \\\\\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "**Verify that these parameters generate data in which an average of 46 to 48 percent of subjects use contraceptives.**\n",
    "\n",
    "$\\text{logit}\\:p_{ij} = \\beta_{0j} + \\beta_1 \\times \\text{urban} + \\beta_2 \\times \\text{living.children} + \\beta_3 \\times \\text{age-mean}$\n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of 10,000 simulations of contraceptive use\n",
      " - Mean = 0.47657\n",
      " - Variance = 0.00001\n",
      " - Std. Dev = 0.00382\n"
     ]
    }
   ],
   "source": [
    "def logit(logit_p):\n",
    "    p = 1/(1 + np.exp(-logit_p))\n",
    "    return p\n",
    "\n",
    "data = read_data_part2()\n",
    "\n",
    "\n",
    "# Hard coded values\n",
    "mu_0 = 2\n",
    "var_0 = 1\n",
    "sigma_0 = np.sqrt(var_0)\n",
    "data['beta_0'] = pd.Series(np.ones(data.shape[0]))\n",
    "\n",
    "betas = []\n",
    "for i in range(60):\n",
    "    betas.append(np.random.normal(mu_0, var_0))\n",
    "    \n",
    "for idx, beta in enumerate(betas):\n",
    "    data.loc[data['district'] == idx, 'beta_0'] = betas[idx]\n",
    "\n",
    "\n",
    "beta = [0, 4, -3, -2]\n",
    "\n",
    "samples = data.shape[0]\n",
    "\n",
    "beta_0 = data['beta_0']\n",
    "urban = data['urban']\n",
    "living_children = data['living.children'] \n",
    "age_mean = data['age_mean']\n",
    "\n",
    "ratio = []\n",
    "for i in range(10000):\n",
    "    logit_p = beta_0 + beta[1]*urban + beta[2]*living_children + beta[3]*age_mean\n",
    "    p = logit(logit_p)\n",
    "    Y = [np.random.binomial(1, pij) for pij in p]\n",
    "    ratio.append(sum(Y)/len(Y))\n",
    "    \n",
    "ratio = np.array(ratio)\n",
    "plt.hist(ratio, bins = 25)\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('% use of contraceptives')\n",
    "plt.title('Histogram of simulated % of women that use contraceptives')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "mean = ratio.mean()\n",
    "var = ratio.var()\n",
    "std = ratio.std()\n",
    "median = np.median(ratio)\n",
    "print('Summary of 10,000 simulations of contraceptive use')\n",
    "print(' - Mean = {:.5f}'.format(mean))\n",
    "print(' - Variance = {:.5f}'.format(var))\n",
    "print(' - Std. Dev = {:.5f}'.format(std))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise-r'>\n",
    "\n",
    "**2.3**  Fit the varying-intercept model specified above to your simulated data. Reasonably good convergence may require adjustments to the number of tuning samples and the target acceptance rate as suggested in pymc3's warnings.\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "\\beta_{0j} &\\sim N(\\mu_0,\\sigma_0^2)\\; \\text{, with} \\;\\; \\mu_0 \\sim N(0,10000)\\; \\text{and} \\; \\; \\frac{1}{\\sigma^2_0} \\sim \\text{Gamma}(0.1,0.1)\n",
    "\\\\\n",
    "\\beta_1 &\\sim N(0,10000) \n",
    "\\\\ \\\\ \n",
    "\\beta_2 &\\sim N(0,10000)\n",
    "\\\\ \\\\ \n",
    "\\beta_3 &\\sim N(0,10000)\n",
    "\\\\ \\\\\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "Model for data:\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "Y_{ij} & \\sim \\text{Bernoulli}(p_{ij})\n",
    "\\\\ \\\\\n",
    "\\text{logit}\\:p_{ij} &= \\beta_{0j} + \\beta_1 \\times \\text{urban} + \\beta_2 \\times \\text{living.children} + \\beta_3 \\times \\text{age-mean}\n",
    "\\\\ \\\\\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "from pymc3 import Model, Normal, HalfNormal, model_to_graphviz\n",
    "from pymc3 import NUTS, sample, find_MAP\n",
    "from scipy import optimize\n",
    "\n",
    "data = read_data_part2()\n",
    "  \n",
    "    \n",
    "# probability model\n",
    "sigma = np.sqrt(10000)\n",
    "with Model() as my_linear_model:\n",
    "    mu_0 = pm.Normal('mu_0', mu=0, sd = sigma)\n",
    "    tau_0 = pm.Gamma('tau_0', alpha=0.1, beta=0.1)\n",
    "    \n",
    "    beta_0 = pm.Normal('beta_0', mu=mu_0, tau=tau_0, shape=60)\n",
    "    beta_1 = pm.Normal('beta_1', mu=0, sd=sigma)\n",
    "    beta_2 = pm.Normal('beta_2', mu=0, sd=sigma)\n",
    "    beta_3 = pm.Normal('beta_3', mu=0, sd=sigma)\n",
    "    \n",
    "    logit_p = beta_0[data['district'].values] + beta_1*data['urban'].values + beta_2*data['living.children'].values + beta_3*data['age_mean'].values\n",
    "    p = logit(logit_p)\n",
    "    Y_obs = pm.Bernoulli(name = 'Y_obs', logit_p=logit_p, observed = Y)\n",
    "\n",
    "display(model_to_graphviz(my_linear_model) )\n",
    "\n",
    "with my_linear_model:\n",
    " \n",
    "    print(f'Starting MCMC process')\n",
    "    # draw 2000 posterior samples and run the default number of chains = 4 \n",
    "    trace = sample(draws = 20000, tune=1000, target_accept=0.975) \n",
    "    print(f'DONE')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise-r'>\n",
    "\n",
    "**2.4**  Plot the trace plots of the MCMC sampler for the parameters $\\mu_0, \\frac{1}{\\sigma^2_0}\\text{ (a.k.a., }\\tau_0\\text{)}, \\beta_1, \\beta_2, \\beta_3$. Based on these and the R-hat values, does it look like the samplers converged?\n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymc3 import traceplot, compareplot, plot_posterior, forestplot\n",
    "traceplot(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.rhat(trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since all of the $\\hat{R}$ values for each parameter is < 1.01, we can conclude that we converged on a common distribution for each parameter in most of the iterations simulated. The plots visually confirm the result. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise-r'>\n",
    "\n",
    "**2.5**  Plot histograms of the posterior distributions for the parameters $\\beta_{0,9}$, $\\beta_{0,19}$, $\\beta_{0,29}$, ..., $\\beta_{0,59}$. Are the actual parameters that you generated contained within these posterior distributions?\n",
    "\n",
    "**Hint: The `az.plot_posterior()` function might be helpful here.**\n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "plots = az.plot_posterior(trace, var_names=['beta_0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise-r'>\n",
    "\n",
    "**2.6**  We now fit our model to the *actual* data. Fit the varying-intercept model to the real training data.\n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "from pymc3 import Model, Normal, HalfNormal, model_to_graphviz\n",
    "from pymc3 import NUTS, sample, find_MAP\n",
    "from scipy import optimize\n",
    "\n",
    "data = read_data_part2()\n",
    "  \n",
    "    \n",
    "# probability model\n",
    "sigma = np.sqrt(10000)\n",
    "with Model() as my_linear_model:\n",
    "    mu_0 = pm.Normal('mu_0', mu=0, sd = sigma)\n",
    "    tau_0 = pm.Gamma('tau_0', alpha=0.1, beta=0.1)\n",
    "    \n",
    "    beta_0 = pm.Normal('beta_0', mu=mu_0, tau=tau_0, shape=60)\n",
    "    beta_1 = pm.Normal('beta_1', mu=0, sd=sigma)\n",
    "    beta_2 = pm.Normal('beta_2', mu=0, sd=sigma)\n",
    "    beta_3 = pm.Normal('beta_3', mu=0, sd=sigma)\n",
    "    \n",
    "    logit_p = beta_0[data['district'].values] + beta_1*data['urban'].values + beta_2*data['living.children'].values + beta_3*data['age_mean'].values\n",
    "    p = logit(logit_p)\n",
    "    Y_obs = pm.Bernoulli(name = 'Y_obs', logit_p=logit_p, observed = data['contraceptive_use'])\n",
    "\n",
    "\n",
    "with my_linear_model:\n",
    " \n",
    "    print(f'Starting MCMC process')\n",
    "    # draw 2000 posterior samples and run the default number of chains = 4 \n",
    "    trace = sample(draws = 20000, tune=1000, target_accept=0.975) \n",
    "    print(f'DONE')\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise-r'>\n",
    "\n",
    "**2.7**  Check the convergence by examining the trace plots and R-hats, as you did with the simulated data. What do you observe?\n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "traceplot(trace)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.rhat(trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THere was better convergence when fitting parameters on the real data and wider variance for $\\beta_0s$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise-r'>\n",
    "\n",
    "**2.8**  Based on the posterior means, which district has the highest base rate of contraceptive usage (independent of other factors like urban population)? Which district has the lowest?\n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = az.summary(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = summary.reset_index()\n",
    "beta0_summary = summary.loc[summary['index'].str.contains('beta_0')]\n",
    "\n",
    "highest = beta0_summary.loc[beta0_summary['mean'] == beta0_summary['mean'].max() ]\n",
    "lowest = beta0_summary.loc[beta0_summary['mean'] == beta0_summary['mean'].min() ]\n",
    "\n",
    "print('District with highest base rate of contraceptive usage is district {}'.format(int(highest['index'].values[0].split('[')[1].split(']')[0])))\n",
    "print('District with(lowest base rate of contraceptive usage is district {}'.format(int(lowest['index'].values[0].split('[')[1].split(']')[0])))\n",
    "# beta0_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise-r'>\n",
    "\n",
    "**2.9**  What are the posterior means of $\\mu_0$ and $\\sigma_0$? Do these values offer any evidence in support of or against the varying-intercept model, compared to a model with a single intercept value for all districts?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_mu_0 = summary.loc[summary['index'].str.contains('mu_0'), 'mean'].values[0]\n",
    "mu_0 = logit(logit_mu_0)\n",
    "\n",
    "logit_tau_0 = summary.loc[summary['index'].str.contains('tau_0'), 'mean'].values[0]\n",
    "tau_0 = logit(logit_tau_0)\n",
    "\n",
    "sigma = np.sqrt(1/tau_0)\n",
    "\n",
    "print('mu_0 = {:.2f}'.format(mu_0))\n",
    "print('tau_0 = {:.2f}'.format(tau_0))\n",
    "print('sigma = {:.2f}'.format(sigma))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part3\"></a>\n",
    "    \n",
    "<!-- <div class=\"alert alert-block alert-danger\" style=\"color:black;background-color:#E7F4FA\"> -->\n",
    "\n",
    "# Part 3: Varying-Coefficients Model and Model Selection\n",
    "\n",
    "[Return to contents](#contents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part3intro\"></a>\n",
    "\n",
    "## Overview \n",
    "\n",
    "[Return to contents](#contents)\n",
    "\n",
    "The next model we will fit to the contraceptives data is a varying-coefficients logistic regression model, where the coefficients on `living.children`, `age_mean`, and `urban` vary by district.\n",
    "\n",
    "Prior distribution:\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "\\beta_{0j} &\\sim N(\\mu_0,\\sigma_0^2)\\; \\text{, with} \\;\\; \\mu_0 \\sim N(0,10000)\\; \\text{and} \\; \\; \\frac{1}{\\sigma^2_0} \\sim \\text{Gamma}(0.1,0.1)\n",
    "\\\\\n",
    "\\beta_{1j} &\\sim N(0,\\sigma_1^2)\\; \\text{, with} \\;\\; \\frac{1}{\\sigma^2_1} \\sim \\text{Gamma}(0.1,0.1) \n",
    "\\\\\n",
    "\\beta_{2j} &\\sim N(0,\\sigma_2^2)\\; \\text{, with} \\;\\; \\frac{1}{\\sigma^2_2} \\sim \\text{Gamma}(0.1,0.1)\n",
    "\\\\ \n",
    "\\beta_{3j} &\\sim N(0,\\sigma_3^2)\\; \\text{, with} \\;\\; \\frac{1}{\\sigma^2_3} \\sim \\text{Gamma}(0.1,0.1)\n",
    "\\\\\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "Model for data:\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "Y_{ij} &\\sim \\text{Bernoulli}(p_{ij})\n",
    "\\\\ \\\\\n",
    "\\text{logit}\\:p_{ij} &= \\beta_{0j} + \\beta_{1j} \\times \\text{urban} + \\beta_{2j} \\times \\text{living.children} + \\beta_{3j} \\times \\text{age-mean}\n",
    "\\\\ \\\\\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "**PLEASE NOTE:** Once again, the $\\text{Gamma}$ distribution uses the $\\text{Gamma}(\\alpha, \\beta)$ parametrization, where $\\alpha$ is the shape and $\\beta$ is the rate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part3questions\"></a>\n",
    "\n",
    "### <div class='exercise'>Part 3: Questions</div> \n",
    "\n",
    "[Return to contents](#contents)\n",
    "\n",
    "**3.1** Fit the varying-coefficients model described above to the real training data.\n",
    "\n",
    "**3.2** Check the convergence of your varying-coefficients model by examining the trace plots and R-hats, as you did with the prior varying-intercepts model. What do you observe?\n",
    "\n",
    "**3.3** Plot the distributions of posterior means and credible intervals for each predictor's coefficient by district. What do you conclude from these graphs?\n",
    "\n",
    "**HINT:** The ArviZ [`plot_forest()`](https://arviz-devs.github.io/arviz/api/generated/arviz.plot_forest.html) function is very well-suited for this task.\n",
    "\n",
    "**3.4** Use all of the information you've gleaned thus far to build Bayesian logistic regression classifiers for both your varying-intercepts model (from 2.7) and your varying-coefficients model (from 3.1). Then, use each model to make predictions on your training and test sets.\n",
    "\n",
    "  - Report each model's classification percentages and accuracy scores on both the training and test sets, as well as the trivial accuracy scores you would achieve with a \"naive\" model that predicts only the most frequent outcome observed in your training data.\n",
    "  \n",
    "  \n",
    "  - What do you observe from these results?\n",
    "  \n",
    "  \n",
    "  - Which model appears to be the best (i.e. varying-intercept or varying-coefficient), and what is your rationale?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part3solutions\"></a>\n",
    "\n",
    "## Part 3: Solutions\n",
    "\n",
    "[Return to contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise-r'>\n",
    "\n",
    "**3.1**  Fit the varying-coefficients model described above to the real training data.\n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise-r'>\n",
    "\n",
    "**3.2**  Check the convergence of your varying-coefficients model by examining the trace plots and R-hats, as you did with the prior varying-intercepts model. What do you observe?\n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**your answer here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise-r'>\n",
    "\n",
    "**3.3**  Plot the distributions of posterior means and credible intervals for each predictor's coefficient by district. What do you conclude from these graphs?\n",
    "\n",
    "**HINT:** The ArviZ [`plot_forest()`](https://arviz-devs.github.io/arviz/api/generated/arviz.plot_forest.html) function is very well-suited for this task.\n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**your answer here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise-r'>\n",
    "\n",
    "**3.4**  Use all of the information you've gleaned thus far to build Bayesian logistic regression classifiers for both your varying-intercepts model (from 2.7) and your varying-coefficients model (from 3.1). Then, use each model to make predictions on your training and test sets.\n",
    "\n",
    "  - Report each model's classification percentages and accuracy scores on both the training and test sets, as well as the trivial accuracy scores you would achieve with a \"naive\" model that predicts only the most frequent outcome observed in your training data.\n",
    "  \n",
    "  \n",
    "  - What do you observe from these results?\n",
    "  \n",
    "  \n",
    "  - Which model appears to be the best (i.e. varying-intercept or varying-coefficient), and what is your rationale?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**your answer here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
