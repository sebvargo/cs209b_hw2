{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <img style=\"float: left; padding-right: 10px; width: 45px\" src=\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/iacs.png\"> CS109B Data Science 2: Advanced Topics in Data Science \n",
    "## Homework 2 (209) - Bayesian: Particle Filters\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Harvard University**<br/>\n",
    "**Spring 2022**<br/>\n",
    "**Instructors**: Mark Glickman & Pavlos Protopapas<br/>\n",
    "**Content**: Kristen Hunter & Blake Bullwinkel\n",
    "\n",
    "\n",
    "<hr style=\"height:2pt\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PLEASE RUN THIS CELL \n",
    "import requests\n",
    "from IPython.core.display import HTML\n",
    "styles = requests.get(\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\").text\n",
    "HTML(styles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"instructions\"></a>\n",
    "\n",
    "<hr style=\"height:2pt\">\n",
    "\n",
    "### INSTRUCTIONS\n",
    "\n",
    "- This homework can be submitted **in pairs**.\n",
    "\n",
    "- To submit your assignment follow the instructions given in Canvas.\n",
    "\n",
    "- Please **restart the kernel and run the entire notebook again before you submit.**\n",
    "\n",
    "- Running cells out of order is a common pitfall in Jupyter Notebooks. To make sure your code continues to work, restart the kernel and rerun your notebook periodically while working through this assignment. \n",
    "\n",
    "- We have tried to include all the libraries you may need to do the assignment in the imports cell provided below. **Please use only the libraries provided in those imports.**\n",
    "\n",
    "- Please use `.head(...)` when viewing data. Do not submit a notebook that is **excessively long**. \n",
    "\n",
    "- In questions that require code to answer, such as \"calculate and report $R^2$\", do not just output the value from a cell. Write a `print(...)` function that clearly labels the output, includes a reference to the calculated value, and rounds it to a reasonable number of digits. **Do not hard code values in your printed output**. For example, this is an appropriate print statement:\n",
    "```python\n",
    "print(f'The R^2 is {R:.4f}')\n",
    "```\n",
    "- **Your plots MUST be clearly labeled and easy to read,** including clear labels for the $x$ and $y$ axes, a descriptive title (\"MSE plot\" is NOT a descriptive title; \"Training and validation MSE at varying degree polynomial regression models\" on the other hand is descriptive), a legend when appropriate, and clearly formatted text and graphics.\n",
    "\n",
    "- **Your code may also be evaluated for efficiency and clarity.** As a result, correct output is not always sufficient for full credit.\n",
    "\n",
    "<hr style=\"height:2pt\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import poisson\n",
    "from IPython.display import display\n",
    "\n",
    "np.random.seed(209)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"contents\"></a>\n",
    "\n",
    "## Notebook Contents\n",
    "\n",
    "- [**Problem 1 [3 pts]: Modeling**](#part1)\n",
    "- [**Problem 2 [3 pts]: Conceptual review**](#part2)\n",
    "- [**Problem 3 [10 pts]: Particle filter**](#part3)\n",
    "- [**Problem 4 [3 pts]: Results**](#part4)\n",
    "- [**Problem 5 [3 pts]: Particles**](#part5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data provided tracks a population of little owls over time. Researchers put out nesting boxes, and at regular time intervals conducted a survey of the population of owls in the nesting boxes.\n",
    "\n",
    "Citation: Fitsum Abadi, Olivier Gimenez, Bruno Ullrich, Raphael Arlettaz, and Michael Schaub. (2010). [Estimation of immigration rate using integrated population models.](https://besjournals.onlinelibrary.wiley.com/doi/abs/10.1111/j.1365-2664.2010.01789.x) Journal of Applied Ecology 47, 393-400.\n",
    "\n",
    "We are interested in estimating the abundance of breeding females in the owl population. We will consider a state-space model/hidden markov model for owl abundance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the owl population data\n",
    "def read_data():\n",
    "    owl = pd.read_csv('data/owls.csv')\n",
    "    return owl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part1\"></a>\n",
    "\n",
    "# Part 1: Modeling \n",
    "\n",
    "[Return to contents](#contents)\n",
    "\n",
    "The *true* population abundance of breeding females at time $t$ is $x_t$. We assume this value is latent/unobserved. The *observed* count of breeding females at time $t$ is $y_t$.\n",
    "\n",
    "The observed count may differ from the true abundance for two reasons.\n",
    "\n",
    "First, the survey could undercount the number of breeding females. Some of the females may not be in the nesting box at the time of the survey, or some could choose to nest elswhere.\n",
    "\n",
    "Second, the survey could overcount the number of breeding females. Female owls begin breeding at 1 year old, and it can be difficult for a researcher to tell if an owl has reached breeding age. Thus, in the survey, some of the females may be incorrectly counted as breeding females even if they are immature.\n",
    "\n",
    "Let’s start with setting up model components. These model components will form the building blocks of a particle filter algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part1questions\"></a>\n",
    "\n",
    "### <div class='exercise'>Part 1: Questions</div> \n",
    "\n",
    "[Return to contents](#contents)\n",
    "\n",
    "**1.1** *Observed counts*: We can model the observed process as a function of the latent process as Poisson, centered on the true abundance.\n",
    "\n",
    "$$\n",
    "y_t | x_t \\sim Pois(x_t)\n",
    "$$\n",
    "\n",
    "Write a function that takes in a value of $x_t$ and a value of $y_t$ and calcutes the probability of the observed $y_t$ conditional on $x_t$.\n",
    "\n",
    "**1.2** *Latent transitions*: We can model the latent process of owl abundance using a Poisson distribution based on the previous time point and a parameter $\\alpha$. Note that for this assignment, we will take $\\alpha$ to be known.\n",
    "\n",
    "$$\n",
    "x_t | x_{t-1} \\sim Pois(\\alpha x_{t-1})\n",
    "$$\n",
    "\n",
    "Write a function that takes in an assumed $\\alpha$ and a latent state $x_{t−1}$ and randomly draws $N$ possible values of $x_t$.\n",
    "\n",
    "**1.3** *Initialization*: Write a function that initializes $N$ possible values of the latent state at time 1 ($x_1$). The values should be drawn from a Poisson distribution with assumed mean `init_lambda`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part1solutions\"></a>\n",
    "## Part 1: Solutions\n",
    "\n",
    "[Return to contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class='exercise-r'>\n",
    "\n",
    "**1.1**  *Observed counts*: We can model the observed process as a function of the latent process as Poisson, centered on the true abundance.\n",
    "\n",
    "$$\n",
    "y_t | x_t \\sim Pois(x_t)\n",
    "$$\n",
    "\n",
    "Write a function that takes in a value of $x_t$ and a value of $y_t$ and calcutes the probability of the observed $y_t$ conditional on $x_t$.\n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03368973499542734"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def p_observation(xt_mu, yt_k):\n",
    "    return poisson.pmf(k = yt_k, mu=xt_mu)\n",
    "\n",
    "p_observation(xt_mu=5, yt_k=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class='exercise-r'>\n",
    "\n",
    "**1.2**  *Latent transitions*: We can model the latent process of owl abundance using a Poisson distribution based on the previous time point and a parameter $\\alpha$. Note that for this assignment, we will take $\\alpha$ to be known.\n",
    "\n",
    "$$\n",
    "x_t | x_{t-1} \\sim Pois(\\alpha x_{t-1})\n",
    "$$\n",
    "\n",
    "Write a function that takes in an assumed $\\alpha$ and a latent state $x_{t−1}$ and randomly draws $N$ possible values of $x_t$.\n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  5,  8,  4,  3,  4,  7,  7,  6,  6,  5,  5,  7,  3,  5,  5,  9,\n",
       "        4,  6,  4, 10,  2, 10,  2,  5,  7,  2,  9,  2,  6,  3,  6,  4,  5,\n",
       "        4,  4,  7,  8,  6,  6,  6,  8,  2,  2,  6,  7,  4,  5,  2,  6,  4,\n",
       "        7,  7,  2,  8,  8,  8,  0,  2,  4,  3,  5,  6,  4,  7,  4,  1,  4,\n",
       "       11,  7,  5, 10,  8,  2,  5,  5,  7,  4,  9,  9,  4,  3,  8,  2,  4,\n",
       "        8,  3,  6,  9,  6])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def transition(xt_prior_mu, alpha, n):\n",
    "    return poisson.rvs(mu=alpha * xt_prior_mu, size=n)\n",
    "\n",
    "transition(xt_prior_mu = 10, alpha = .5, n = 90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class='exercise-r'>\n",
    "\n",
    "**1.3**  *Initialization*: Write a function that initializes $N$ possible values of the latent state at time 1 ($x_1$). The values should be drawn from a Poisson distribution with assumed mean `init_lambda`.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 2, 1, 2, 1, 4, 2, 1, 1, 3])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def initialize(n, init_lambda):\n",
    "    x1 = transition(init_lambda, alpha=1, n = n)\n",
    "    return x1\n",
    "\n",
    "initialize(10, 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part2\"></a>\n",
    "\n",
    "# Part 2: Conceptual review\n",
    "\n",
    "Note: these questions can be briefly answered with 1-3 sentences.\n",
    "\n",
    "[Return to contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part2questions\"></a>\n",
    "\n",
    "### <div class='exercise'>Part 2: Questions</div> \n",
    "\n",
    "[Return to contents](#contents)\n",
    "\n",
    "**2.1** Why does this setting lend itself to a particle filter?\n",
    "\n",
    "**2.2** What is the purpose of the resampling step in particle filters?\n",
    "\n",
    "**2.3** What could happen if you forgot to normalize weights before conducting resampling?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part2solutions\"></a>\n",
    "## Problem 2: Solutions\n",
    "\n",
    "[Return to contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class='exercise-r'>\n",
    "\n",
    "**2.1**  Why does this setting lend itself to a particle filter?\n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think the main reason is because we are approximating a value that we will be never be able to determine with 100% certainty, i.e.: the true population of breeding owls. We infer what the \"true\" value could be based its the empirical evidence (observable samples). Finally a state space model is useful in this case because the \"true\" value is not static and is always changing because there are breeding owls that die and young owls that mature at an unknown (or unmeasurable rate). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class='exercise-r'>\n",
    "\n",
    "**2.2**  What is the purpose of the resampling step in particle filters?\n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since you are updating the probability using a latent transition model, you need to resample your data with the updated probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class='exercise-r'>\n",
    "\n",
    "**2.3**  What could happen if you forgot to normalize weights before conducting resampling?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we did not normalized and resampled using multinomial sampling, some values would not be picked ever. By normalizing we guarantee that even the smallest values will have a chance to be sampled again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id=\"part3\"></a>\n",
    "\n",
    "# Part 3: Particle Filter \n",
    "\n",
    "[Return to contents](#contents)\n",
    "\n",
    "\n",
    "We will focus on the problem of filtering, which means we are interested in the distribution of the latent states conditional on the observed states. Specifically, we interested in the distribution $p(x_t∣y_{1:t})$, where $y_{1:t}$ denotes the vector of all observed time points from $1$ to $t$. Assume there are $T$ total time points, and we are interested in the latent states over all time points: $p(x_1∣y_1)$, $p(x_2∣y_{1:2})$, up to $p(x_T∣y_{1:T})$.\n",
    "\n",
    "In particular, our inference target is the posterior mean at each time point: $\\mu_t = E(x_t∣y_{1:t})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part3questions\"></a>\n",
    "\n",
    "### <div class='exercise'>Part 3: Questions</div> \n",
    "\n",
    "[Return to contents](#contents)\n",
    "\n",
    "**3.1** *Setup*: Before we begin, we will need one more function for the particle filter algorithm. Write a function that takes in a vector of values and a vector of weights, and performs multinomial resampling.\n",
    "\n",
    "**3.2** *Algorithm*: Write a particle filter function for conducting inference on the latent state $x_t$ conditional on $y_{1:t}$ for each time point $t=1$ to $T$. Your function should return a $T$-length vector called `mu_hat` that contains the estimated posterior mean, $\\hat{\\mu}_t$, at each time point. Begin at time $t=1$ and initialize the particles. At the end of this step, you will have filled out the first value of $\\hat{\\mu}$. Then, finish the algorithm for time $t>1$ to $T$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Solutions\n",
    "\n",
    "[Return to contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class='exercise-r'>\n",
    "\n",
    "**3.1**  *Setup*: Before we begin, we will need one more function for the particle filter algorithm. Write a function that takes in a vector of values and a vector of weights, and performs multinomial resampling.\n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[100, 100, 100, 80, 80, 100, 80, 100, 100, 80]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def resample(X=None, W=[1,1,1]):\n",
    "    resampling_ls = []\n",
    "    W = np.array(W)\n",
    "    # normalize weights\n",
    "    normalized_w = W/sum(W)\n",
    "    \n",
    "    # array with cumulative sum of weights\n",
    "    cumsum = 0\n",
    "    cum_weights = []\n",
    "    for w in normalized_w:\n",
    "        cumsum += w\n",
    "        cum_weights.append(cumsum)\n",
    "\n",
    "    # randomly pick number between 0 and 1\n",
    "    picks = np.random.uniform(0,1, size=len(W))\n",
    "    \n",
    "    # resample based on normalized weights \n",
    "    for pick in picks:\n",
    "        for w in sorted(cum_weights):\n",
    "            if pick > w: continue\n",
    "            else: \n",
    "                idx_to_sample = np.where(cum_weights == w)[0][0]\n",
    "                resampling_ls.append(X[idx_to_sample])\n",
    "                break\n",
    "            \n",
    "    return resampling_ls\n",
    "\n",
    "resample(X = [10,30,80,80,80,80, 80, 100, 10, 10], W = [1,3,8, 8, 8, 8, 8, 10, 1, 1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class='exercise-r'>\n",
    "\n",
    "**3.2**  *Algorithm*: Write a particle filter function for conducting inference on the latent state $x_t$ conditional on $y_{1:t}$ for each time point $t=1$ to $T$. Your function should return a $T$-length vector called `mu_hat` that contains the estimated posterior mean, $\\hat{\\mu}_t$, at each time point. Begin at time $t=1$ and initialize the particles. At the end of this step, you will have filled out the first value of $\\hat{\\mu}$. Then, finish the algorithm for time $t>1$ to $T$.\n",
    "\n",
    "The arguments to your function should include `alpha`, the number of particles `N`, and `init_lambda`.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part4\"></a>\n",
    "\n",
    "# Part 4: Results\n",
    "\n",
    "[Return to contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part4questions\"></a>\n",
    "\n",
    "### <div class='exercise'>Part 4: Questions</div> \n",
    "\n",
    "[Return to contents](#contents)\n",
    "\n",
    "**4.1** Run your function with `alpha = 1.1`,  `N = 30`, and `init_lambda = 9`. Then, plot both the observed counts $y_t$ and the estimated posterior mean $\\hat{\\mu}_t$ values over time. Briefly comment on the plot: do you see any patterns? Do you have any intution behind the patterns you see? (1-2 sentences is sufficient).\n",
    "\n",
    "**4.2** How do the results change as you change $N$ to be larger or smaller? Explain any patterns you see.\n",
    "\n",
    "**4.3** How do the results change as you change `init_lambda` to be larger or smaller? Explain any patterns you see."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part4solutions\"></a>\n",
    "## Part 4: Solutions\n",
    "\n",
    "[Return to contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class='exercise-r'>\n",
    "\n",
    "**4.1**  Run your function with `alpha = 1.1`,  `N = 30`, and `init_lambda = 9`. Then, plot both the observed counts $y_t$ and the estimated posterior mean $\\hat{\\mu}_t$ values over time. Briefly comment on the plot: do you see any patterns? Do you have any intution behind the patterns you see? (1-2 sentences is sufficient).\n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**your answer here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class='exercise-r'>\n",
    "\n",
    "**4.2**  How do the results change as you change `N` to be larger or smaller? Explain any patterns you see.\n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**your answer here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class='exercise-r'>\n",
    "\n",
    "**4.3**  How do the results change as you change `init_lambda` to be larger or smaller? Explain any patterns you see.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**your answer here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part5\"></a>\n",
    "\n",
    "# Part 5: Particles \n",
    "\n",
    "Let's consider the resampling step in more detail.\n",
    "\n",
    "[Return to contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part5questions\"></a>\n",
    "\n",
    "### <div class='exercise'>Part 5: Questions</div> \n",
    "\n",
    "[Return to contents](#contents)\n",
    "\n",
    "**5.1** The function was modified to track how many *unique* values are taken by the collection of particles at each time point (after resampling). (Note: no need to do this yourself). The results are below.\n",
    "\n",
    "```\n",
    "[ 8 10  9 10 11 10 10  8  9  8 10  8  9  9  7 10  9  8  9  8  8  7 11  9\n",
    " 10 12]\n",
    "```\n",
    "\n",
    "How does the number of unique values compare to the number of particles? Is there a pattern for how the number of unique values varies over time?\n",
    "\n",
    "**5.2** The algorithm was re-run with `alpha = 1.5`. The following is again the number of unique values:\n",
    "\n",
    "```\n",
    "[ 9  7  7 10  6  4  6  5  6  2  2  6  5  3  5  4  1  1  2  1  3  1  3  3\n",
    "  3  2]\n",
    "```\n",
    "\n",
    "How has the number of unique values changed? Do you see patterns in the number of unique values as the algorithm progresses? Explain why we are tracking this number, and how it could impact the success of the algorithm–do you still trust inference about $\\hat{\\mu}_t$?\n",
    "\n",
    "**5.3** Try to rerun your function with `alpha = 3`. Does your function still run? If it doesn’t, explain why you think it isn’t succeeding. If it does, explain why the algorithm might still be experiencing problems. The number of unique values has changed when we change `alpha`. What does this tell you about the modeling assumptions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part5solutions\"></a>\n",
    "\n",
    "## Part 5: Solutions\n",
    "\n",
    "[Return to contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class='exercise-r'>\n",
    "\n",
    "**5.1**  The function was modified to track how many *unique* values are taken by the collection of particles at each time point (after resampling). (Note: no need to do this yourself). The results are below.\n",
    "\n",
    "```\n",
    "[ 8 10  9 10 11 10 10  8  9  8 10  8  9  9  7 10  9  8  9  8  8  7 11  9\n",
    " 10 12]\n",
    "```\n",
    "\n",
    "How does the number of unique values compare to the number of particles? Is there a pattern for how the number of unique values varies over time?\n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**your answer here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class='exercise-r'>\n",
    "\n",
    "**5.2**  The algorithm was re-run with `alpha = 1.5`. The following is again the number of unique values:\n",
    "\n",
    "```\n",
    "[ 9  7  7 10  6  4  6  5  6  2  2  6  5  3  5  4  1  1  2  1  3  1  3  3\n",
    "  3  2]\n",
    "```\n",
    "\n",
    "How has the number of unique values changed? Do you see patterns in the number of unique values as the algorithm progresses? Explain why we are tracking this number, and how it could impact the success of the algorithm–do you still trust inference about $\\hat{\\mu}_t$?\n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**your answer here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class='exercise-r'>\n",
    "\n",
    "**5.3**  Try to rerun your function with `alpha = 3`. Does your function still run? If it doesn’t, explain why you think it isn’t succeeding. If it does, explain why the algorithm might still be experiencing problems. The number of unique values has changed when we change `alpha`. What does this tell you about the modeling assumptions?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**your answer here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**THE END!** 🦉"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
